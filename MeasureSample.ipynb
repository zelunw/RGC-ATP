{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e74ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:38:30.731601Z",
     "iopub.status.busy": "2023-11-05T00:38:30.731601Z",
     "iopub.status.idle": "2023-11-05T00:38:33.549960Z",
     "shell.execute_reply": "2023-11-05T00:38:33.549960Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches \n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from cellpose import utils\n",
    "from scipy import signal\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename, askdirectory\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os.path as path \n",
    "import xml.etree.ElementTree as ET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55ad94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:38:33.552084Z",
     "iopub.status.busy": "2023-11-05T00:38:33.552084Z",
     "iopub.status.idle": "2023-11-05T00:38:34.017615Z",
     "shell.execute_reply": "2023-11-05T00:38:34.017615Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read delay\n",
    "try:\n",
    "    delay = pd.read_csv('delay.txt', header=None).values[0][0] * 1.07 \n",
    "except OSError:\n",
    "    delay = 0\n",
    "    print('delay.txt not found, setting delay = 0')\n",
    "\n",
    "\n",
    "#Select post seg\n",
    "post_filename_list = []\n",
    "for filename in os.listdir():\n",
    "    if '_seg.npy' in filename:\n",
    "        post_filename_list.append(filename)\n",
    "if len(post_filename_list) == 1:\n",
    "    post_npy_filename = post_filename_list[0]\n",
    "else:\n",
    "    #Select POST inputs if more than one `_seg.npy` file in current directory\n",
    "    Tk().withdraw() \n",
    "    post_npy_filename = askopenfilename(title = 'Select POSTtime _seg.npy')\n",
    "\n",
    "post_npy = np.load(post_npy_filename, allow_pickle=True).item()\n",
    "print('post_npy_filename = ' + post_npy_filename)\n",
    "\n",
    "\n",
    "#Select pre seg\n",
    "pre_npy_filename = path.abspath(path.join(os.getcwd() ,\"../..\")) + '\\\\pre\\\\registered0\\\\reg_concat_chAvg_sliceAvg_seg.npy'\n",
    "try:\n",
    "    pre_dir = os.path.dirname(pre_npy_filename)\n",
    "    pre_npy = np.load(pre_npy_filename, allow_pickle=True).item()\n",
    "    print('pre_npy_filename = ' + pre_npy_filename)\n",
    "except OSError:\n",
    "    pre_npy_filename = '' #overwrite\n",
    "    print('No pretime _seg.npy selected; proceeding without pretime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639bcbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:38:34.019753Z",
     "iopub.status.busy": "2023-11-05T00:38:34.019753Z",
     "iopub.status.idle": "2023-11-05T00:38:34.180987Z",
     "shell.execute_reply": "2023-11-05T00:38:34.180851Z"
    }
   },
   "outputs": [],
   "source": [
    "#Match somas\n",
    "\n",
    "if pre_npy_filename == '': #here, create `df` using the number of masks in post_npy, with all indices being equal\n",
    "    print('No pretime processed, no traces matched') \n",
    "\n",
    "    df = pd.DataFrame([])\n",
    "    df['variable'] = list(range(0, len(np.delete(np.unique(post_npy['masks']), 0)))) #using python indexing, n = # of masks in post_npy, first ROI index = 0\n",
    "    df['TRACK_ID'] = list(range(0, len(np.delete(np.unique(post_npy['masks']), 0))))\n",
    "    df['INDEX_0'] = list(range(0, len(np.delete(np.unique(post_npy['masks']), 0))))\n",
    "    df['INDEX_1'] = list(range(0, len(np.delete(np.unique(post_npy['masks']), 0))))\n",
    "    df[['INDEX_0','INDEX_1']] = df[['INDEX_0','INDEX_1']].astype(np.int16)\n",
    "\n",
    "else:\n",
    "    #Get total number of tracks, for cases where tracks are filtered out\n",
    "    tree = ET.parse('TrackmateInput.xml')\n",
    "    root = tree.getroot()\n",
    "    xml_dict_list = []\n",
    "    for var in root.iter('Track'):\n",
    "        xml_dict_list.append(var.attrib)\n",
    "    FinalTrackIndex = int(xml_dict_list[-1]['TRACK_INDEX']) #0-based indexing, from Trackmate\n",
    "    \n",
    "    for csv_name in os.listdir():\n",
    "        if 'export.csv' in csv_name:\n",
    "            df_filename = csv_name\n",
    "            \n",
    "    df = pd.read_csv(df_filename)\n",
    "    df = df.iloc[3:]\n",
    "    df = df[['TRACK_ID','FRAME','MEDIAN_INTENSITY_CH1']] #reads values as str\n",
    "    df[['TRACK_ID','FRAME','MEDIAN_INTENSITY_CH1']] = df[['TRACK_ID','FRAME','MEDIAN_INTENSITY_CH1']].astype(np.float64)\n",
    "    df[['TRACK_ID','FRAME','MEDIAN_INTENSITY_CH1']] = df[['TRACK_ID','FRAME','MEDIAN_INTENSITY_CH1']].astype(np.int16)\n",
    "    df['MEDIAN_INTENSITY_CH1'] = df['MEDIAN_INTENSITY_CH1'] - 1 #subtract 1 to match python indexing\n",
    "    df = df.rename(columns={'MEDIAN_INTENSITY_CH1': 'INDEX'})\n",
    "\n",
    "    df.loc[df['FRAME'] == 0, 'INDEX_0'] = df['INDEX']\n",
    "    df.loc[df['FRAME'] == 1, 'INDEX_1'] = df['INDEX']\n",
    "\n",
    "    df = df[['TRACK_ID','INDEX_0','INDEX_1']]\n",
    "\n",
    "    id_vars = ['TRACK_ID']\n",
    "    melted = df.melt(id_vars=id_vars).dropna()\n",
    "    pivoted = melted.pivot_table(index=id_vars, columns=\"variable\", values=\"value\")\n",
    "\n",
    "    df = pivoted.reset_index()\n",
    "    df[['INDEX_0','INDEX_1']] = df[['INDEX_0','INDEX_1']].astype(np.int16)\n",
    "\n",
    "    #track indices in CSV (only includes tracks with pre and post spots) are the new matched ROI indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424edb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:38:34.976636Z",
     "iopub.status.busy": "2023-11-05T00:38:34.976636Z",
     "iopub.status.idle": "2023-11-05T00:38:38.552725Z",
     "shell.execute_reply": "2023-11-05T00:38:38.552725Z"
    }
   },
   "outputs": [],
   "source": [
    "#read pre\n",
    "\n",
    "if pre_npy_filename == '':\n",
    "    print('No pretime processed')\n",
    "else:\n",
    "    now_dir = os.getcwd()\n",
    "    os.chdir(pre_dir)\n",
    "\n",
    "    dat = pre_npy\n",
    "    chan0 = io.imread('reg_concat_ch0.tif') \n",
    "    chan1 = io.imread('reg_concat_ch1.tif')\n",
    "\n",
    "    chan0_list = []\n",
    "    chan1_list = []\n",
    "\n",
    "    for n in np.delete(np.unique(dat['masks']), 0):\n",
    "\n",
    "        ypix_loop = np.where(dat['masks'] == n)[0]\n",
    "        xpix_loop = np.where(dat['masks'] == n)[1]\n",
    "\n",
    "        chan0_sig = np.average(chan0[:,ypix_loop ,xpix_loop ], axis = 1) \n",
    "        chan1_sig = np.average(chan1[:,ypix_loop ,xpix_loop ], axis = 1) \n",
    "\n",
    "        chan0_list.append(chan0_sig)\n",
    "        chan1_list.append(chan1_sig)\n",
    "    \n",
    "    chan0_array = np.vstack(chan0_list)\n",
    "    chan1_array = np.vstack(chan1_list)\n",
    "\n",
    "    data_array_pre = np.stack((chan0_array, chan1_array))\n",
    "    PreFrmsBegin = 0\n",
    "    PreFrmsCalcd = 120\n",
    "    data_array_pre = data_array_pre[:,:, PreFrmsBegin : PreFrmsBegin+PreFrmsCalcd ]\n",
    "\n",
    "    os.chdir(now_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae125d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:38:38.554773Z",
     "iopub.status.busy": "2023-11-05T00:38:38.554773Z",
     "iopub.status.idle": "2023-11-05T00:38:39.409217Z",
     "shell.execute_reply": "2023-11-05T00:38:39.409217Z"
    }
   },
   "outputs": [],
   "source": [
    "#filtering pre\n",
    "\n",
    "if pre_npy_filename == '':\n",
    "    print('No pretime processed')\n",
    "else:\n",
    "    #20 frms moving average boxcar window convolution implementation\n",
    "    nfrms = 20              \n",
    "    win = signal.windows.boxcar(nfrms)\n",
    "    data_array_pre_filt = np.apply_along_axis(lambda m: signal.convolve(m, win, mode='valid') / sum(win) , axis=2, arr=(data_array_pre)) \n",
    "    nan_array = np.full([2, np.shape(data_array_pre)[1], int(nfrms/2)], np.nan) \n",
    "    data_array_pre_filt = np.concatenate((nan_array, data_array_pre_filt, nan_array), axis = 2)\n",
    "    \n",
    "#plotting    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    \n",
    "    plt.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(2,3, figsize = (15,10))\n",
    "    \n",
    "    axs[0,0].plot(np.transpose(data_array_pre[0]))\n",
    "    axs[0,0].set_title('CFP Unfiltered')\n",
    "        \n",
    "    axs[1,0].plot(np.transpose(data_array_pre_filt[0]))\n",
    "    axs[1,0].set_title('CFP 20 frms mov avg')\n",
    "        \n",
    "    axs[0,1].plot(np.transpose(data_array_pre[1]))\n",
    "    axs[0,1].set_title('YFP Unfiltered')\n",
    "    \n",
    "    axs[1,1].plot(np.transpose(data_array_pre_filt[1]))\n",
    "    axs[1,1].set_title('YFP 20 frms mov avg')\n",
    "    \n",
    "    axs[0,2].plot(np.transpose(data_array_pre[1]/data_array_pre[0]))\n",
    "    axs[0,2].set_title('FRET Unfiltered')\n",
    "    \n",
    "    axs[1,2].plot(np.transpose(data_array_pre_filt[1]/data_array_pre_filt[0]))\n",
    "    axs[1,2].set_title('FRET 20 frms mov avg')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c752a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:38:39.411231Z",
     "iopub.status.busy": "2023-11-05T00:38:39.411231Z",
     "iopub.status.idle": "2023-11-05T00:38:39.793521Z",
     "shell.execute_reply": "2023-11-05T00:38:39.793521Z"
    }
   },
   "outputs": [],
   "source": [
    "#intensity QC pre\n",
    "\n",
    "if pre_npy_filename == '':\n",
    "    print('No pretime processed')\n",
    "else:\n",
    "\n",
    "    data_array_pre_filt_NaNremoved = data_array_pre_filt[:,:, ~np.isnan(data_array_pre_filt[0,0,:]) ]\n",
    "    intensity_array_pre = (data_array_pre_filt_NaNremoved[1]+data_array_pre_filt_NaNremoved[0])/2\n",
    "    print( np.shape(     np.median( intensity_array_pre , axis = 1 )    ) )\n",
    "    cutoff = 50 \n",
    "\n",
    "    plt.hist(np.median( intensity_array_pre , axis = 1 ), bins = 110)\n",
    "    plt.axvline(cutoff, color = 'black')\n",
    "    plt.show()\n",
    "\n",
    "    #QC by ROI pixel count\n",
    "    roiPixelCount_list = []\n",
    "    for n in np.delete(np.unique(pre_npy['masks']), 0):\n",
    "        ypix_loop = np.where(pre_npy['masks'] == n)[0]\n",
    "        roiPixelCount_list.append(len(ypix_loop))\n",
    "    roiPixelCount_list_PRE = roiPixelCount_list\n",
    "\n",
    "    passQC_pre = np.intersect1d( np.where(np.median( intensity_array_pre , axis = 1 ) > cutoff)[0]   ,   np.where(np.array(roiPixelCount_list_PRE) > 100) )\n",
    "    print( np.shape(passQC_pre) )\n",
    "\n",
    "    inputs = [pre_npy] \n",
    "    for dat in inputs:\n",
    "        outlines = utils.outlines_list(dat['masks'])\n",
    "        plt.figure(dpi=120)\n",
    "        plt.imshow(dat['img'])\n",
    "        for o in outlines:\n",
    "            plt.plot(o[:,0], o[:,1], color='r', linewidth = 0.3) \n",
    "        for o in (outlines[p] for p in passQC_pre):                                            \n",
    "            plt.plot(o[:,0], o[:,1], color='white', linewidth = 0.3)   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0607f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:38:39.795585Z",
     "iopub.status.busy": "2023-11-05T00:38:39.795585Z",
     "iopub.status.idle": "2023-11-05T00:39:17.582015Z",
     "shell.execute_reply": "2023-11-05T00:39:17.582015Z"
    }
   },
   "outputs": [],
   "source": [
    "#post timelapse\n",
    "\n",
    "dat = post_npy\n",
    "\n",
    "chan0 = io.imread('reg_concat_regToPre_ch0.tif') \n",
    "chan1 = io.imread('reg_concat_regToPre_ch1.tif')\n",
    "chan0_list = []\n",
    "chan1_list = []\n",
    "\n",
    "for n in np.delete(np.unique(dat['masks']), 0):\n",
    "\n",
    "    ypix_loop = np.where(dat['masks'] == n)[0]\n",
    "    xpix_loop = np.where(dat['masks'] == n)[1]\n",
    "\n",
    "    chan0_sig = np.average(chan0[:,ypix_loop ,xpix_loop ], axis = 1) \n",
    "    chan1_sig = np.average(chan1[:,ypix_loop ,xpix_loop ], axis = 1) \n",
    "                                                                     \n",
    "    chan0_list.append(chan0_sig)\n",
    "    chan1_list.append(chan1_sig)\n",
    "           \n",
    "chan0_array = np.vstack(chan0_list)\n",
    "chan1_array = np.vstack(chan1_list)\n",
    "\n",
    "data_array = np.stack((chan0_array, chan1_array))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa95660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:39:17.584087Z",
     "iopub.status.busy": "2023-11-05T00:39:17.584087Z",
     "iopub.status.idle": "2023-11-05T00:39:19.345391Z",
     "shell.execute_reply": "2023-11-05T00:39:19.345391Z"
    }
   },
   "outputs": [],
   "source": [
    "#filtering post\n",
    "\n",
    "win = signal.windows.boxcar(nfrms) # `nfrms` defined earlier in `filtering pre` \n",
    "data_array_filt = np.apply_along_axis(lambda m: signal.convolve(m, win, mode='valid') / sum(win) , axis=2, arr=(data_array))\n",
    "nan_array = np.full([2, np.shape(data_array)[1], int(nfrms/2)], np.nan) \n",
    "data_array_filt = np.concatenate((nan_array, data_array_filt, nan_array), axis = 2)\n",
    "\n",
    "#plotting    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    \n",
    "plt.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize = (15,10))\n",
    "\n",
    "axs[0,0].plot(np.transpose(data_array[0]))\n",
    "axs[0,0].set_title('CFP Unfiltered')\n",
    "    \n",
    "axs[1,0].plot(np.transpose(data_array_filt[0]))\n",
    "axs[1,0].set_title('CFP 20 frms mov avg')\n",
    "    \n",
    "axs[0,1].plot(np.transpose(data_array[1]))\n",
    "axs[0,1].set_title('YFP Unfiltered')\n",
    "\n",
    "axs[1,1].plot(np.transpose(data_array_filt[1]))\n",
    "axs[1,1].set_title('YFP 20 frms mov avg')\n",
    "\n",
    "axs[0,2].plot(np.transpose(data_array[1]/data_array[0]))\n",
    "axs[0,2].set_title('FRET Unfiltered')\n",
    "\n",
    "axs[1,2].plot(np.transpose(data_array_filt[1]/data_array_filt[0]))\n",
    "axs[1,2].set_title('FRET 20 frms mov avg')\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d62235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:39:19.347438Z",
     "iopub.status.busy": "2023-11-05T00:39:19.347438Z",
     "iopub.status.idle": "2023-11-05T00:39:19.813843Z",
     "shell.execute_reply": "2023-11-05T00:39:19.813843Z"
    }
   },
   "outputs": [],
   "source": [
    "#intensity QC post\n",
    "\n",
    "data_array_filt_NaNremoved = data_array_filt[:,:, ~np.isnan(data_array_filt[0,0,:]) ]\n",
    "intensity_array = (data_array_filt_NaNremoved[1]+data_array_filt_NaNremoved[0])/2\n",
    "print( np.shape(     np.median( intensity_array , axis = 1 )    ) )\n",
    "cutoff = 50\n",
    "\n",
    "plt.hist(np.median( intensity_array , axis = 1 ), bins = 75)\n",
    "plt.axvline(cutoff, color = 'black')\n",
    "plt.show()\n",
    "\n",
    "#QC by ROI pixel count\n",
    "roiPixelCount_list = []\n",
    "for n in np.delete(np.unique(post_npy['masks']), 0):\n",
    "    ypix_loop = np.where(post_npy['masks'] == n)[0]\n",
    "    roiPixelCount_list.append(len(ypix_loop))\n",
    "roiPixelCount_list_POST = roiPixelCount_list\n",
    "\n",
    "passQC_post =  np.intersect1d( np.where(np.median( intensity_array , axis = 1 ) > cutoff)[0]   ,   np.where(np.array(roiPixelCount_list_POST) > 100) )\n",
    "print( np.shape(passQC_post) )\n",
    "\n",
    "inputs = [post_npy]\n",
    "for dat in inputs:\n",
    "    outlines = utils.outlines_list(dat['masks'])\n",
    "    plt.figure(dpi=120)\n",
    "    plt.imshow(dat['img'])\n",
    "    for o in outlines:\n",
    "        plt.plot(o[:,0], o[:,1], color='r', linewidth = 0.3) \n",
    "    for o in (outlines[p] for p in passQC_post):                                            \n",
    "        plt.plot(o[:,0], o[:,1], color='white', linewidth = 0.3)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d7a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:39:19.815918Z",
     "iopub.status.busy": "2023-11-05T00:39:19.815918Z",
     "iopub.status.idle": "2023-11-05T00:39:21.467870Z",
     "shell.execute_reply": "2023-11-05T00:39:21.467870Z"
    }
   },
   "outputs": [],
   "source": [
    "#create masked arrays\n",
    "\n",
    "if pre_npy_filename == '':\n",
    "    print(\"no pretime processed\")\n",
    "\n",
    "    mask_post = np.ones(np.shape(    data_array_filt    ), bool)\n",
    "    mask_post[:, passQC_post, :] = False\n",
    "    data_array_filt_masked = np.ma.MaskedArray(data_array_filt, mask_post)\n",
    "\n",
    "else:\n",
    "\n",
    "    mask_pre = np.ones(np.shape(     data_array_pre_filt    ), bool) \n",
    "    mask_pre[:, passQC_pre, :] = False \n",
    "    data_array_pre_filt_masked = np.ma.MaskedArray(data_array_pre_filt, mask_pre) #Non Matched, QC'd\n",
    "    \n",
    "    mask_post = np.ones(np.shape(    data_array_filt    ), bool)\n",
    "    mask_post[:, passQC_post, :] = False\n",
    "    data_array_filt_masked = np.ma.MaskedArray(data_array_filt, mask_post)\n",
    "\n",
    "    #Matched, QC'd\n",
    "    MATCHED_data_array_pre_filt_masked = data_array_pre_filt_masked[:,df.INDEX_0.values,:] \n",
    "    MATCHED_data_array_filt_masked = data_array_filt_masked[:,df.INDEX_1.values,:]\n",
    "    mask_union_index = np.union1d(np.where(MATCHED_data_array_pre_filt_masked.mask.all(axis=0).all(axis=1))[0], \n",
    "            np.where(MATCHED_data_array_filt_masked.mask.all(axis=0).all(axis=1))[0])\n",
    "    MATCHED_data_array_pre_filt_masked[:,mask_union_index,:] = np.ma.masked  #overwrite\n",
    "    MATCHED_data_array_filt_masked[:,mask_union_index,:] = np.ma.masked\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0420c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_csv\n",
    "\n",
    "data_array_filt_masked #filt, QC'd, nonMATCHED\n",
    "unmatched_PostFRET = data_array_filt_masked[1]/data_array_filt_masked[0]\n",
    "pd.DataFrame(unmatched_PostFRET).to_csv('Unmatched_FRET_POST.csv', header=False, index=False)\n",
    "\n",
    "MATCHED_data_array_filt_masked #filt, QC'd, MATCHED\n",
    "PostFRET = MATCHED_data_array_filt_masked[1]/MATCHED_data_array_filt_masked[0]\n",
    "pd.DataFrame(PostFRET).to_csv('Matched_FRET_POST.csv', header=False, index=False)\n",
    "\n",
    "data_array_pre_filt_masked  \n",
    "unmatched_PreFRET = data_array_pre_filt_masked[1]/data_array_pre_filt_masked[0]\n",
    "pd.DataFrame(unmatched_PreFRET).to_csv('Unmatched_FRET_PRE.csv', header=False, index=False)\n",
    "\n",
    "MATCHED_data_array_pre_filt_masked\n",
    "PreFRET = MATCHED_data_array_pre_filt_masked[1]/MATCHED_data_array_pre_filt_masked[0]\n",
    "pd.DataFrame(PreFRET).to_csv('Matched_FRET_PRE.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
